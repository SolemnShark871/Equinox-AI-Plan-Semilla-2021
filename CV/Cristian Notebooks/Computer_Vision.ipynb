{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer_Vision.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y0_LC-yB7onZ",
        "kcRRk-pNBekV",
        "cWqLA70nHkEA",
        "XzVvnSvVHl4i",
        "kfqm-VVfHl7m",
        "LJcWZ1eIHl99",
        "jy5SWorfQUz4",
        "Pvvu6k8oHmAR",
        "kuPkrjIXHmC5",
        "MpCRFgNHHmFo",
        "-2MVUCGpHmIY",
        "bmMSNwPTHmLX",
        "AocU43rIHmNx",
        "us-QWO8aHmQm",
        "t6D-vUGBHmTh",
        "lr0OocwFHmWJ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk_CARTO3q9o"
      },
      "source": [
        "# Plan Semilla 2021 - 2\n",
        "\n",
        "\n",
        "<img src=\"https://asesoftware.sharepoint.com/:i:/r/sites/PreventaAI/Documentos%20compartidos/6.Recursos%20Gra%CC%81ficos%20Imagen%20Equinox/Logo%20Equinox/Logo%20Equinox%20Original%201.png?csf=1&web=1&e=sa5TIy\" width=\"200\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6daLBrtD3t96"
      },
      "source": [
        "# Computer vision\n",
        "\n",
        "<img src=\"https://asesoftware.sharepoint.com/:i:/r/sites/PreventaAI/Documentos%20compartidos/6.Recursos%20Gra%CC%81ficos%20Imagen%20Equinox/Logos%20Servicios/Computer%20Vision.png?csf=1&web=1&e=ehW0EZ\" width=\"200\"> \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0_LC-yB7onZ"
      },
      "source": [
        "## Introduction to convolutional neural network\n",
        "<img src=\"https://asesoftware.sharepoint.com/:i:/r/sites/PreventaAI/Documentos%20compartidos/6.Recursos%20Gra%CC%81ficos%20Imagen%20Equinox/Ada/Ada%2011.png?csf=1&web=1&e=6ajN8q\" width=\"200\"> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j59GV1xBO10U"
      },
      "source": [
        "### Image Understanding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD6YOXCCPfla"
      },
      "source": [
        "![pixelArray](https://ai.stanford.edu/~syyeung/cvweb/Pictures1/imagematrix.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPnqsmMEPXoB"
      },
      "source": [
        "![grayScale](https://i.stack.imgur.com/B2DBy.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoSkg9w6O9gB"
      },
      "source": [
        "![ImageLayers](https://static.electronicsweekly.com/wp-content/uploads/2018/08/21105734/Manchester-RGB-RGCV-display.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcRRk-pNBekV"
      },
      "source": [
        "### Applications\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWybPdLIDziP"
      },
      "source": [
        "![applications](https://www.researchgate.net/profile/Dae-Young-Kang/publication/346091812/figure/fig5/AS:979480482955270@1610537753983/Computer-vision-tasks-Adapted-from.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Supplementary Material:\n",
        "\n",
        "[27+ Most Popular Computer Vision Applications and Use Cases in 2021](https://www.v7labs.com/blog/computer-vision-applications)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jbLP_z9B_Lt"
      },
      "source": [
        "### Artificial Neural Network Limitations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txVBsHo6HUKD"
      },
      "source": [
        "<image src =\"https://asesoftware.sharepoint.com/:i:/r/sites/PreventaAI/Documentos%20compartidos/6.Recursos%20Gra%CC%81ficos%20Imagen%20Equinox/Ada/Ada%209.png?csf=1&web=1&e=N9XUyF\" width=200 align=\"right\">\n",
        "\n",
        "\n",
        "\n",
        "- Lossing Spacial Coherence Information\n",
        "\n",
        "- Network size (CNN is smaller)\n",
        "\n",
        "- Bigger computing capability required\n",
        "\n",
        "- Problem solving using different architectures\n",
        "\n",
        "- Easier objects generalization \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWqLA70nHkEA"
      },
      "source": [
        "## Data Managment\n",
        "<image src=\"https://asesoftware.sharepoint.com/:i:/r/sites/PreventaAI/Documentos%20compartidos/6.Recursos%20Gra%CC%81ficos%20Imagen%20Equinox/Ada/Ada%2012.png?csf=1&web=1&e=Q4nGps\" width=200 align=\"center\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzVvnSvVHl4i"
      },
      "source": [
        "### Data adquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP-EIGXBNMTq"
      },
      "source": [
        "- Good quality images\n",
        "\n",
        "![blur](https://pyimagesearch.com/wp-content/uploads/2015/09/detecting_blur_header.jpg)\n",
        "\n",
        "- different points of view \n",
        "\n",
        "![pointOfView](https://media.istockphoto.com/photos/set-cups-different-angles-picture-id1176410813)\n",
        "\n",
        "- Ambient light conditions\n",
        "\n",
        "![light](https://nofilmschool.com/sites/default/files/styles/facebook/public/moods.jpg?itok=RyE69ix-)\n",
        "\n",
        "- Object occlusion\n",
        "\n",
        "![occlusion](https://i.stack.imgur.com/v9zhy.jpg)\n",
        "\n",
        "- Lot of images\n",
        "\n",
        "![lot](https://neurohive.io/wp-content/uploads/2019/01/dd-e1547642312239.jpg)\n",
        "\n",
        "- Public DataSets\n",
        "\n",
        "![dataset](https://i0.wp.com/syncedreview.com/wp-content/uploads/2020/06/Imagenet.jpg?fit=1400%2C600&ssl=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfqm-VVfHl7m"
      },
      "source": [
        "### Data PreProcessing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4VfQVdpTlmF"
      },
      "source": [
        "- Filtering\n",
        "- All images to same shape\n",
        "- Cleaning\n",
        "- Same format\n",
        "- Not corrupted images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJcWZ1eIHl99"
      },
      "source": [
        "### Data Labeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ckeR3s6Tri5"
      },
      "source": [
        "- The most boring task, but the most importat task, the value are not just in the image quality, labeling the images give us the information to train any model.\n",
        "\n",
        "- It's important to define rules, to label any image correctly, for example minimun 50% of the object visible. Those rules depends on kind of problem you want to solve.\n",
        "\n",
        "- Object detection\n",
        "\n",
        "![labelIMG](https://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo3.jpg)\n",
        "\n",
        "- Segmentation\n",
        "\n",
        "![Segmentation](https://camo.githubusercontent.com/5f495baf75cafc48aff2d39594a44e5d47a983b33c7b275aa608410a12f898cf/68747470733a2f2f692e696d6775722e636f6d2f6d34526d6a43702e676966)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy5SWorfQUz4"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJIDkO1fVXe1"
      },
      "source": [
        "Most of the time, it's difficult to take photos with all of previous requirements, so basically we need to augment the number of images, modifying their characteristics artificially:\n",
        "\n",
        "- flip\n",
        "\n",
        "![flip](https://nanonets.com/blog/content/images/2018/11/1_-beH1nNqlm_Wj-0PcWUKTw.jpeg)\n",
        "\n",
        "- rotation\n",
        "\n",
        "![rotation](https://cdn-images-1.medium.com/max/720/1*i_F6aNKj3yggkcNXQxYA4A.jpeg)\n",
        "\n",
        "- crop\n",
        "\n",
        "![crop](https://cdn-images-1.medium.com/max/720/1*ypuimiaLtg_9KaQwltrxJQ.jpeg)\n",
        "\n",
        "- noise\n",
        "\n",
        "![noise](https://cdn-images-1.medium.com/max/720/1*cx24OpSNOwgg7ULUHKiGnA.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvvu6k8oHmAR"
      },
      "source": [
        "## Convolutional Neural Network\n",
        "<image src=\"https://asesoftware.sharepoint.com/:i:/r/sites/PreventaAI/Documentos%20compartidos/6.Recursos%20Gra%CC%81ficos%20Imagen%20Equinox/Ada/Ada%2013.png?csf=1&web=1&e=22zYJL\" width=200>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuPkrjIXHmC5"
      },
      "source": [
        "### Convolution Operation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywa6ELU0YrXq"
      },
      "source": [
        "Convolution in a neural network uses a kernel to highlight specific features of an image. So to enhance different features you need to use different kernels at same time.\n",
        "\n",
        "![Kernel](https://i.stack.imgur.com/Bxix6.png)\n",
        "\n",
        "Kernel size need to be smaller than image size, to process all image you use a slicing window, the result of that are a new image with specific feature highlighted\n",
        "\n",
        "![filters](https://miro.medium.com/max/1838/1*X14h2keMe_qe72YQ2pKipA.png)\n",
        "\n",
        "If we use 32 filters (same as kernel), the results are 32 images. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpCRFgNHHmFo"
      },
      "source": [
        "### CNN architecture (Classification)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbSfgAAbafXg"
      },
      "source": [
        "The CNN architecture its based in to parts, the fearture extraction part and the classification/detection/segmentation part. \n",
        "\n",
        "![parts](https://developer.nvidia.com/sites/default/files/pictures/2018/convolutional_neural_network.png)\n",
        "\n",
        "In most cases the feature extraction could be the same to any purpose. The feature extration combine diferent layers of convolution process, keep in mind that each image generated in previous layer need to be processed later, then, the number of parameters increase and the memory to allocate those images too.\n",
        "\n",
        "![MaxPooling2D](https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png)\n",
        "\n",
        "Between each layer it's common to use some kind of pooling, the results is a smaller image, minimizing the loss of information, because the convolution process previouly enhance the relevant part of the image.\n",
        "\n",
        "![resulting images](https://miro.medium.com/max/1400/1*uAeANQIOQPqWZnnuH-VEyw.jpeg)\n",
        "\n",
        "\n",
        "To complete de architecture it's necesary to add the second part, if it's a classification or detection task, you could use a fully connected network to process the features generated previously, and the output layer of the complete network will differs depending on the task. On the otheer hand, if is segmentation task, you need to use a encoder/decoder arquitecture o some kind of transpose convolution to generate the new image.\n",
        "\n",
        "![coderDecoder](https://www.researchgate.net/profile/Yasmina-Souley-Dosso/publication/330234950/figure/fig1/AS:718336946102275@1548276282892/SegNet-Deep-Convolutional-Neural-Network-for-semantic-segmentation-An-image-is-inputed.ppm)\n",
        "\n",
        "It this notebook we don't go deeper in those arquitectures, but many deep learning and computer vision courses are waiting for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2MVUCGpHmIY"
      },
      "source": [
        "## Computer Vision Techniques\n",
        "\n",
        "<image src=\"https://asesoftware.sharepoint.com/:i:/r/sites/PreventaAI/Documentos%20compartidos/6.Recursos%20Gra%CC%81ficos%20Imagen%20Equinox/Ada/Ada%206.png?csf=1&web=1&e=vpcGWf\" width=200>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmMSNwPTHmLX"
      },
      "source": [
        "### Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc0YPP0KjRNw"
      },
      "source": [
        "- Architecture \n",
        "\n",
        "![classification](https://miro.medium.com/max/1400/1*CnNorCR4Zdq7pVchdsRGyw.png)\n",
        "\n",
        "- Example: \n",
        "\n",
        "![example_classification](https://raw.githubusercontent.com/floydhub/image-classification-template/master/images/classification.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AocU43rIHmNx"
      },
      "source": [
        "### Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtXG6xD8jlub"
      },
      "source": [
        "- Architecture\n",
        "\n",
        "![yoloV4](https://static-01.hindawi.com/articles/js/volume-2021/5576262/figures/5576262.fig.005.svgz)\n",
        "\n",
        "- Example Numerate \n",
        "\n",
        "![detection](https://is2-ssl.mzstatic.com/image/thumb/PurpleSource114/v4/bd/0c/cf/bd0ccff9-7265-d733-90d4-789e8fcdba57/0af67ef1-03ad-497a-a9c6-5aafe129ff8b_ipad4.png/576x768bb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us-QWO8aHmQm"
      },
      "source": [
        "### Semantic Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kh1HW0dk0US"
      },
      "source": [
        "- Architecture:\n",
        "\n",
        "![semantic](https://www.researchgate.net/profile/Vasu-Sharma/publication/318740383/figure/fig1/AS:521035784757248@1501236019989/Fully-Convolutional-Neural-Networks-for-Semantic-segmentation.png)\n",
        "\n",
        "\n",
        "- Example:\n",
        "\n",
        "![semanticexample](https://nanonets.com/blog/content/images/2020/08/1_wninXztJ90h3ZHtKXCNKFA.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6D-vUGBHmTh"
      },
      "source": [
        "### Instance Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Nlr6i7mkUH"
      },
      "source": [
        "- Architecture\n",
        "\n",
        "![instance](https://static.packt-cdn.com/products/9781838827069/graphics/assets/2884d889-f0b0-44e5-83cf-22ec8797f59a.png)\n",
        "\n",
        "- Example:\n",
        "\n",
        "![instanceExample](https://miro.medium.com/max/1400/1*1cYZ22FDqbyxWjRwSG6dRA.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0OocwFHmWJ"
      },
      "source": [
        "### Other techniques (RL, GANs, Style Transfer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI-qIuLboMIH"
      },
      "source": [
        "![other](https://neurohive.io/wp-content/uploads/2019/06/Screenshot-from-2019-06-15-02-03-02-570x235.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7ajbjDSgZEg"
      },
      "source": [
        "### Tranfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2T7fNlAiUiM"
      },
      "source": [
        "\n",
        "![other](https://miro.medium.com/proxy/1*1CxVzTNILTHgDs5yJO4W9A.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-QOujISoNVe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}